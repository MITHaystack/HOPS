#!@PY_EXE@

#core imports
import argparse
import sys
import os
import math
import re

#non-core imports
#set the plotting back-end to 'agg' to avoid display
import matplotlib as mpl
mpl.use('Agg')
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.colorbar as mcbar
import matplotlib.cm as cmx
from matplotlib.ticker import MultipleLocator, FormatStrFormatter

#HOPS module imports
import vpal.processing
import vpal.utility
import vpal.fringe_file_manipulation

import hops_test as ht


################################################################################

def main():

    parser = argparse.ArgumentParser(
        prog='generate_session_summary.py', \
        description='''utility to extract data from fringe files and construct a .csv summary file (like an alist file)''' \
        )

    parser.add_argument('control_file', help='the control file to be applied to all scans')
    parser.add_argument('stations', help='concatenated string of single character codes for all stations to be fringe fit')
    parser.add_argument('pol_product', help='the polarization-product to be fringe fit')
    parser.add_argument('experiment_directory', help='relative path to directory containing experiment data')

    parser.add_argument('-n', '--numproc', type=int, dest='num_proc', help='number of concurrent fourfit jobs to run, default=1', default=1)
    parser.add_argument('-p', '--progress', action='store_true', dest='use_progress_ticker', help='monitor process with progress indicator', default=False)
    parser.add_argument('-b', '--begin-scan', dest='begin_scan_limit', help='limit the earliest scan to be used e.g 244-1719', default="000-0000")
    parser.add_argument('-e', '--end-scan', dest='end_scan_limit', help='limit the latest scan to be used, e.g. 244-2345', default="999-9999")
    parser.add_argument('-o', '--output-filename', dest='output_filename', help='name of output csv file', default="session_summary.csv")
    
    parser.add_argument('-q', '--quick', action='store_true', dest='quick', help='do not run fourfit or check control file hash, just load all fringe files', default=False)

    args = parser.parse_args()
    control_file = args.control_file
    stations = args.stations
    polprod = args.pol_product
    exp_dir = args.experiment_directory
    outfile = args.output_filename

    abs_exp_dir = os.path.abspath(exp_dir)
    exp_name = os.path.split(os.path.abspath(exp_dir))[1]

    quick_mode = args.quick 

    #determine all possible baselines
    baseline_list = vpal.processing.construct_valid_baseline_list(abs_exp_dir, stations[0], stations[1:], network_reference_baselines_only=False)
    print("all possible baselines: ", baseline_list)
    
    #needed for plot-naming
    control_file_stripped = re.sub('[/\.]', '', control_file)
    
    #pol product:
    if polprod not in ['XX', 'YY', 'XY', 'YX', 'I']:
        print("polarization product must be one of: XX, YY, XY, YX, or I")
        sys.exit(1)
    
    #loop over fringe files and generate summary dataframes
    summary_dataframe_list = list()
    
    if quick_mode:
        print("quick mode enabled: ignoring control file matching, will not run fourfit, looking for pre-existing fringe files.")

    for bline in baseline_list:
        ff_list = []

        if quick_mode:
            #just search for fringe files associated with this baseline
            flist = ht.recursive_find_fringe_files(os.path.abspath(exp_dir) )
            for ff in flist:
                if bline in ff:
                    fhandle = vpal.fringe_file_manipulation.FringeFileHandle()
                    fhandle.load(ff)
                    ff_list.append(fhandle)

        #not in quick mode, may need to run fourfit
        else: 
            #default output filename
            if not os.path.isfile(os.path.abspath(control_file)):
                print("could not find control file: ", control_file)
                sys.exit(1)
            #collect/compute fringe files, and apply cuts
            print("processing baseline: ", bline)
            set_commands = "set gen_cf_record true"
            ff_list = vpal.processing.load_and_batch_fourfit( \
                os.path.abspath(exp_dir), bline[0], bline[1], os.path.abspath(control_file), set_commands, \
                num_processes=args.num_proc, start_scan_limit=args.begin_scan_limit, \
                stop_scan_limit=args.end_scan_limit, pol_products=[polprod], use_progress_ticker=args.use_progress_ticker \
            )
            print("n fringe files  =", str(len(ff_list)))

        #load what fringe files we have into the summary list/dataframe
        if len(ff_list) == 0:
            print("Error: no fringe files available, skipping baseline: ", bline)
        else:
            for ff in ff_list:
                ff_sum = ff.get_summary()
                #convert to dataframe
                ff_df = pd.DataFrame(ff_sum, index=[0])
                summary_dataframe_list.append(ff_df)

    #merge the dataframes of each scan
    all_scan_df = pd.concat(summary_dataframe_list)

    #sort by time_tag
    all_scan_df.sort_values(by=['time_tag', 'baseline'], inplace=True)

    print(all_scan_df)

    #dump to file
    all_scan_df.to_csv(outfile, sep=',', index=False, encoding='utf-8')


if __name__ == '__main__':          # official entry point
    main()
    sys.exit(0)
